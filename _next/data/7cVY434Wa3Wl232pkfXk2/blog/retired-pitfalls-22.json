{"pageProps":{"item":{"id":"retired-pitfalls-22","title":"Retiring old performance pitfalls","author":"John Högberg","excerpt":"\nErlang/OTP 22 will bring many performance improvements to the table, but most\nof them have a broad impact and don't affect the way you write efficient code.\nIn this post I'd like to highlight a few things that used to be surprisingly\nslow but no longer need to be avoided.","article_date":1541548800000,"tags":["erts compiler"],"frontmatter":{"layout":"post","title":"Retiring old performance pitfalls","tags":"erts compiler","author":"John Högberg"},"content":"\nErlang/OTP 22 will bring many performance improvements to the table, but most\nof them have a broad impact and don't affect the way you write efficient code.\nIn this post I'd like to highlight a few things that used to be surprisingly\nslow but no longer need to be avoided.\n\n### Named fun recursion\n\nNamed funs have a neat little feature that might not be obvious at a first\nglance; their name is a variable like any other and you're free to pass it to\nanother function or even return it.\n\n```erlang\ndeepfoldl(F, Acc0, L) ->\n    (fun NamedFun([_|_]=Elem, Acc) -> lists:foldl(NamedFun, Acc, Elem);\n         NamedFun([], Acc) -> Acc;\n         NamedFun(Elem, Acc) -> F(Elem, Acc)\n     end)(L, Acc0).\n```\n\nThis is cool but a bit of a headache for the compiler. To create a fun we pass\nits definition and free variables to a `make_fun2` instruction, but we can't\ninclude the fun itself as a free variable because it hasn't been created yet.\nPrior to OTP 22 we solved this by creating a new equivalent fun _inside_ the\nfun, but this made recursion surprisingly expensive both in terms of run-time\nand memory use.\n\nAs of OTP 22 we translate recursion to a direct function call instead which\navoids creating a new fun. Other cases still require recreating the fun, but\nthey're far less common.\n\n[Optimize named funs and fun-wrapped macros #1973](https://github.com/erlang/otp/pull/1973)\n\n### List subtraction with large operands (-- operator)\n\nWhile the Erlang VM appears to be pre-emptively scheduled to the programmer,\nit's [co-operatively scheduled](https://en.wikipedia.org/wiki/Computer_multitasking#Cooperative_multitasking)\ninternally. When a native function runs it monopolizes the scheduler until it\nreturns, so a long-running one can severely harm the responsiveness of the\nsystem. We've therefore written nearly all such functions in a style that\nbreaks the work into short units that complete quickly enough, but there's\na steadily shrinking list of functions that misbehave, and list subtraction\nwas one of these.\n\nIt's usually pretty straightforward to rewrite functions in this style, but\nthe [old algorithm](https://github.com/erlang/otp/blob/d9682b02b81fa6e23e554b6e017650eb89ecebed/erts/emulator/beam/erl_bif_lists.c#L195)\nprocessed the second list in a loop around the first list, which is problematic\nsince both lists can be very long and resuming work in nested loops is often\ntrickier than expected.\n\nIn this case it was easier to just get rid of the nested loop altogether. The\nnew algorithm starts out by building a red-black tree from the right-hand side\nbefore removing elements from the left-hand side. As all operations on the tree\nhave `log n` complexity we know that they will finish really quickly, so all we\nneed to care about is yielding in the outer loops.\n\nThis also had the nice side-effect of reducing the worst-case complexity from\n`O(n²)` to `O(n log n)` and let us remove some warnings from the reference\nmanual and [efficiency guide](http://erlang.org/documentation/doc-10.1/doc/efficiency_guide/commoncaveats.html#operator-----). It's worth noting\nthat the new implementation is always faster than the proposed workarounds, and\nthat it falls back to the old algorithm when it's faster to do so.\n\nThis change will be rolled out in OTP 21.2, big thanks to\nDmytro Lytovchenko (@kvakvs on GitHub) for writing the better half of it!\n\n[Optimize list subtraction (A -- B) and make it yield on large inputs #1998](https://github.com/erlang/otp/pull/1998)\n\n### Lookahead in bit-syntax matching\n\nThe optimization pass for bit-syntax matching was completely rewritten in OTP\n22 to take advantage of the new SSA-based intermediate format. It applies the\nsame optimizations as before so already well-optimized code is unlikely to see\nany benefit, but it manages to apply them in far more cases.\n\nFor those who aren't familiar, all bit-syntax matching operates on a\n[\"match context\"](http://erlang.org/doc/efficiency_guide/binaryhandling.html#matching-binaries)\ninternally, which is a mutable object that keeps track of the current\nmatch position. This helps a lot when matching complicated patterns as it can\nzip back and forth as required, saving us from having to match components more\nthan once.\n\nThis is great when matching several different patterns, but it comes in real\nhandy in loops like the following:\n\n```erlang\ntrim_zero(<<0,Tail/binary>>) -> trim_zero(Tail);\ntrim_zero(B) when is_binary(B) -> B.\n```\n\nAs the compiler can see that `Tail` is passed directly to `trim_zero`, which\npromptly begins with a bit-match, it can skip extracting `Tail` as a sub-binary\nand pass the match context instead. This is a pretty well-known optimization\ncalled \"match context reuse\" which greatly improves performance when applied,\nand a lot of code has been written with it in mind.\n\nThe catch of passing a match context like this is that we have to maintain the\nillusion that we're dealing with an immutable _binary_. Whenever it's used in\na non-matching expression we either need to convert the context to an\nequivalent binary, or admit defeat and skip the optimization.\n\nWhile the compiler did a pretty good job prior to OTP 22 it gave up a bit too\neasily in many cases, and the most trivial example is almost funny:\n\n```erlang\ncalls_wrapper(<<\"hello\",Tail/binary>>) ->\n    count_ones(Tail).\n\n%% This simple wrapper prevents context reuse in the call above. :(\ncount_ones(Bin) -> count_ones_1(Bin, 0).\n\ncount_ones_1(<<1, Tail/binary>>, Acc) -> count_ones_1(Tail, Acc + 1);\ncount_ones_1(<<_, Tail/binary>>, Acc) -> count_ones_1(Tail, Acc);\ncount_ones_1(<<>>, Acc) -> Acc.\n```\n\nA trickier example can be found in the `string` module:\n\n```erlang\nbin_search_inv_1(<<CP1/utf8, BinRest/binary>>=Bin0, Cont, Sep) ->\n    case BinRest of\n        %% 1\n        <<CP2/utf8, _/binary>> when ?ASCII_LIST(CP1, CP2) ->\n            case CP1 of\n                Sep ->\n                    %% 2\n                    bin_search_inv_1(BinRest, Cont, Sep);\n                _ ->\n                    %% 3\n                    [Bin0|Cont]\n            end;\n        %% ... snip ...\n```\n\nWhat we're looking at is a fast-path for ASCII characters; when both `CP1` and\n`CP2` are ASCII we know that `CP1` is not a part of a grapheme cluster and we\ncan thus avoid a call to `unicode_util:gc/1`. It's not a particularly expensive\nfunction but calling it once per character adds up quickly.\n\nAt first glance it might seem safe to pass the context at `2`, but this is made\ndifficult by `Bin0` being returned at `3`. As contexts are mutable and change\ntheir position whenever a match succeeds, naively converting `Bin0` back to a\nbinary would give you what comes after `CP2` instead.\n\nNow, you might be wondering why we couldn't simply restore the position before\nconverting `Bin0` back to a binary. It's an obvious thing to do but before OTP\n22 the context tracked not only the current position but also previous ones\nneeded when backtracking. These were saved in per-context \"slots\" which were\nmutable and heavily reused, and the match at `1` clobbered the slot needed to\nrestore `Bin0`.\n\nThis also meant that a context couldn't be used again after being passed to\nanother function or entering a `try`/`catch`, which made it more or less\nimpossible to apply this optimization in code that requires looking ahead.\n\nAs of OTP 22 these positions are stored outside the context so there's no need\nto worry about them becoming invalid, making it possible to optimize the above\ncases.\n\n[Rewrite BSM optimizations in the new SSA-based intermediate format #1958](https://github.com/erlang/otp/pull/1958)\n"}},"__N_SSG":true}