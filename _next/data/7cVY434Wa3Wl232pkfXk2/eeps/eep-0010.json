{"pageProps":{"index":{"id":"0010","content":"<pre><code>Author: Patrik Nyblom &lt;pan(at)erlang(dot)org&gt;\nStatus: Draft\nType: Standards Track\nCreated: 07-may-2008\nErlang-Version: R12B-4\nPost-History: 01-jan-1970\n</code></pre>\n\n<hr />\n\n<h2><a href=\"/eeps/eep-0000\" title=\"EEP Index\">EEP</a> 10: <a href=\"eep-0010.md\" title=\"EEP Source\"> Representing Unicode characters in Erlang</a></h2>\n\n<h1>Abstract</h1>\n\n<p>This EEP suggest a standard representation of <a href=\"http://www.unicode.org/\" title=\"The Unicode homepage, containing downloadable versions of the standard(s)\">Unicode</a> characters in\nErlang, as well as the basic functionality to deal with them.</p>\n\n<h1>Motivation</h1>\n\n<p>As Unicode characters are more widely used, the need for a common\nrepresentation of Unicode characters in Erlang arise. Up until now,\nthe Erlang programmer writing Unicode programs has to decide on\nhis or her own representation and has little or no help from the\nstandard libraries. </p>\n\n<p>Implementing functions in the libraries dealing with all possible\ncombinations and variants of Unicode representation in Erlang is\nconsidered both extremely time consuming and confusing to the future\nuser of the standard library.</p>\n\n<p>One common representation, dealing both with binaries and lists is\ntherefore desirable, making Unicode handling in the standard libraries\neasier to implement and giving a more stringent result.</p>\n\n<p>Once the representation is agreed upon, implementation can be done\nincrementally. This EEP only outlines the most basic functionality the\nsystem should provide. The Unicode support is by no means complete if\nthis EEP is implemented, but implementation will be feasible.</p>\n\n<p>The EEP also suggests library functions and bit syntax to deal with\nalternative encodings. However, one <em>standard</em> encoding is suggested,\nwhich will be what library functions in Erlang are expected to\nsupport, while other representations are supported only in terms of\nconversion.</p>\n\n<h1>Rationale</h1>\n\n<h2>Preconditions</h2>\n\n<p>Erlang traditionally represents text strings as lists of bytes (8bit\nentities),  where the characters are encoded in ISO-8859-1 (latin1). </p>\n\n<p>As the use of Unicode characters gets more widely spread, the demand\nfor a common view of how to represent Unicode characters in Erlang\narise.</p>\n\n<p>Unicode is a character encoding standard where all known, living and\nhistorical written languages are represented in one single character\nset, which of course results in characters demanding more than eight\nbits each for representation.</p>\n\n<h2>Lists</h2>\n\n<p>Regardless of the representation, the Unicode character set is a\nsuper-set of the latin1 ditto, while latin1 in it's turn is a super-set\nof the traditional 7-bit US-ASCII character set. Representing Unicode\ncharacters in Erlang lists is therefore quite naturally done by\nallowing characters in lists to take on values higher than 255.</p>\n\n<p>Therefore a Unicode string can, in Erlang, be conveniently stored\nas a list where each element represents one single Unicode\ncharacter. The following list:</p>\n\n<pre><code>_ex1:\n\n[1050,1072,1082,1074,\n 1086,32,1077,32,85,110,105,99,111,100,101,32,63]\n</code></pre>\n\n<p>- would represent the Bulgarian translation of \"What is Unicode ?\" (which\nlooks something like like \"KAKBO e Unicode ?\" with only the last part\nin latin letters). The last part\n(<code>[32,85,110,105,99,111,100,101,32,63]</code>) is plain latin1 as the string\n\"Unicode ?\" is written in latin letters, while the first part contains\ncharacters not to be represented in a single byte. In essence, the\nstring is encoded in the Unicode encoding standard UTF-32, one\n32bit entity for each character, which is more than sufficient for one\nUnicode character per position.</p>\n\n<p>However, the currently most common representation of Unicode\ncharacters is <a href=\"http://www.ietf.org/rfc/rfc3629.txt\" title=\"The UTF-8 RFC\">UTF-8</a>, in which the characters are stored in one to\nfour 8-bit entities organized in such way that plain 7-bit US ASCII is\nuntouched, while characters 128 and upwards are split over more than\none byte. The advantage of this coding is that e.g. characters having\na meaning to the file/operating system are kept intact and that many\nstrings in western languages do not occupy more space when transformed\ninto Unicode. In such an encoding, the above mentioned Bulgarian\nstring (ex1_) would be represented as the list\n<code>[208,154,208,176,208,186,208,178,208,\n190,32,208,181,32,85,110,105,99,111,100,101,32,63]</code>, where the first\npart, containing the Bulgarian script letters occupy more bytes per\ncharacter, while the trailing part \"Unicode ?\" is identical to the\nplain and more intuitive encoding of one character per list element.</p>\n\n<p>In spite of being less intuitive, the UTF-8 encoding is the one most\nwidely spread and supported by operating systems and terminal\nemulators. UTF-8 is therefore the most convenient way to communicate\ntext to external entities (files, drivers, terminals and so on).</p>\n\n<p>When dealing with lists in Erlang, the advantages of using one list\nelement per character seems to be greater than the advantage of not\nhaving to convert a UTF-8 character string before e.g. printing\nit on a terminal. This is especially true as the current Erlang\nimplementation allows for all current Unicode characters to\noccupy the same memory space as a latin1 character would (bearing in\nmind that each character is represented as an integer and the list\nelement can contain integers up to 16#7ffffff on 32-bit\nimplementations, which is far larger than the largest current Unicode\ncharacter 16#10ffff). A further advantage is that routines like\nio:format can easily cope with latin1 characters and Unicode\ncharacters alike, as the eight-bit characters of Unicode happen\nto correspond exactly to the latin1 character set. It would seem as\nlists have a very natural way of dealing with Unicode characters.</p>\n\n<h2>Binaries</h2>\n\n<p>Binaries on the other hand would suffer greatly from a scheme where\nevery character is encoded with a fixed width capable of representing\nnumbers up to 16#10ffff. The standardized way of doing this would be\nwhat's commonly referred to as UTF-32, i.e. one 32-bit word for each\ncharacter. Even a UTF-16 representation would guarantee to double the\nmemory requirements for all text strings encoded in binaries, while\nUTF-8 would for most common cases be the most space-saving\nrepresentation. </p>\n\n<p>Binaries are often used to represent data to be sent\nto external programs, which also speaks in favor of the UTF-8\nrepresentation. </p>\n\n<p>There are however problems with the UTF-8 representation, most\nobviously the fact that characters occupy a variable number of\npositions (bytes) in the binary, so that traversal is somewhat more\ntedious. An extension to the bit syntax where UTF-8 characters can be\nmatched in the head of a string conveniently would ease up the\nsituation, but as of today, no such primitives are present. UTF-8\nencoded characters are also only backward compatible with 7-bit US-ASCII,\nand there are only probabilistic approaches to determining if a\nsequence of bytes represent Unicode characters encoded as UTF-8 or\nplain latin1. A library function in Erlang therefore needs to be\ninformed about the way characters are encoded in a binary to be able\nto interpret them correctly. A latin1 character above 128 will be\ndisplayed incorrectly if written to a terminal set for displaying\nUTF-8 encoded Unicode and v.v. As a common example\nio:format(\"~s~n\",[MyBinaryString]), would need to be informed about\nthe fact that the string is encoded in UTF-8 or latin1 to display it\ncorrectly on a terminal. \nThe formatting functions actually present a whole set of challenges\nregarding Unicode characters. New formatting controls will be needed\nto inform the formatting functions in the io and io_lib modules that \nstrings are in Unicode or that input is in UTF-8. This is however\nsolvable, as discussed below.</p>\n\n<p>My conclusion so far is that as binaries are often used to save space\nand commonly utilized when communicating with external entities, the\nUTF-8 advantages seem to supersede the disadvantages in the\nbinary case. It therefore seems sensible to commonly encode Unicode\ncharacters in binaries as UTF-8. Of course any\nrepresentation is possible, but UTF-8 would be the most common\ncase and can therefore be regarded as the Erlang standard\nrepresentation.</p>\n\n<h2>Combinations of lists and binaries</h2>\n\n<p>To furthermore complicate things, Erlang has the concept of\niolist's (or iodata). An io_list is any (or almost any) combination of integers\nand binaries representing a sequence of bytes, like i.e\n<code>[[85],110,[105,[99]],111,&lt;&lt;100,101&gt;&gt;]</code> as a\nrepresentation of the string \"Unicode\". When sending data to drivers\nand in many BIFs this rather convenient representation is accepted\n(convenient when constructing, less convenient when traversing).</p>\n\n<p>When dealing with Unicode strings, a similar abstraction would be\ndesirable, and with the above suggested conventions, that would mean\nthat a Unicode character string could be a list with any combination\nof integers ranging from 0 to 16#10ffff and binaries with Unicode\ncharacters encoded as UTF-8. Converting such data to a plain list or a\nplain UTF-8 binary would be easily done as long as one knows how the\ncharacters are encoded to begin with. It would however not necessarily\nbe an iolist. Furthermore conversion functions need to be aware of\nthe original intention of the list to behave correctly. If one wants\nto convert an iolist containing latin1 characters in both list part\nand binary part to UTF-8, the list part cannot be misinterpreted, as\nlatin1 and Unicode are alike for all latin1 characters, but the binary\npart can, as latin1 characters above 127 are encoded in two bytes if\nthe binary contains UTF-8 encoded characters, but only one byte when\nlatin1 encoding is used. The same of course holds for other encodings,\nif a binary encoded in UTF-32 would be converted to UTF-8, the process\nalso would differ from the process of converting latin1 characters.</p>\n\n<p>If we stick with the idea of representing Unicode as one character per\nlist element in lists and as UTF-8 in binaries, we could have the\nfollowing definitions:</p>\n\n<ul>\n<li>A latin1 list: a list containing characters in the range 0..255</li>\n<li>A latin1 binary: a binary consisting of bytes each representing one\n           letter in the ISO-8859-1 character set.</li>\n<li>A Unicode list: a list consisting solely of integers in the range\n              0..16#10ffff.</li>\n<li>A Unicode binary: a binary with Unicode characters encoded\n                     as UTF-8</li>\n<li>A mixed latin1 list: a possibly deep list containing any combination\n                   of integers in the range 0..255 and latin1 binaries.</li>\n<li>A mixed Unicode list: a possibly deep list containing integers in the\n                    range 0..16#10ffff and Unicode binaries.</li>\n</ul>\n\n<h2>Conversion routines</h2>\n\n<p>Conversion functions between latin1 lists and latin1 binaries as well\nas from mixed latin1 lists to latin1 binaries are already present in\nthe system as list<em>to</em>binary, binary<em>to</em>list, and iolist<em>to</em>binary.</p>\n\n<p>Conversion between Unicode lists, Unicode binaries, and from\nmixed Unicode lists could in a similar way be provided by functions like:</p>\n\n<pre><code>unicode:list_to_utf8(UM) -&gt; Bin\n</code></pre>\n\n<p>Where UM is a mixed Unicode list and the result is a UTF-8 binary, and:</p>\n\n<pre><code>unicode:utf8_to_list(Bin) -&gt; UL\n</code></pre>\n\n<p>Where Bin is a binary consisting of Unicode characters encoded as\nUTF-8 and UL is a plain list of Unicode characters.</p>\n\n<p>To allow for conversion to and from latin1 the functions:</p>\n\n<pre><code>unicode:latin1_list_to_utf8(LM) -&gt; Bin\n</code></pre>\n\n<p>and:</p>\n\n<pre><code>unicode:latin1_list_to_unicode_list(LM) -&gt; UL\n</code></pre>\n\n<p>would do the same job. Actually latin1<em>list</em>to_list is not necessary\nin this context, as it is more of an iolist-function, but should be \npresent for completeness.</p>\n\n<p>The fact that lists of integers representing latin1 characters are a\nsubset of the lists containing Unicode characters might however be more\nconfusing than useful to utilize when converting from mixed lists to\nUTF-8 coded binaries. I think a good approach would be to\ndifferentiate the functions dealing with latin1 characters and Unicode\nso that mixed lists are expected to contain only numbers 0..255 if the\nbinaries are expected to contain latin1 bytes. For functions like\nio:format, the same thing should be true i.e. ~s means latin1 mixed\nlists and ~ts means Unicode mixed lists (with binaries in\nUTF-8). Passing a list with an integer > 255 to ~s would be an error\nwith this approach, just like passing the same thing to\n<code>latin1_list_to_utf8/1</code>. See below for more discussions about the io system. </p>\n\n<p>The <code>unicode_list_to_utf8/1</code> and <code>latin1_list_to_utf8/1</code> functions can be \ncombined into the single function <code>list_to_utf8/2</code> like this:</p>\n\n<pre><code>unicode:characters_to_binary(ML,InEncoding) -&gt; binary()\n  ML := A mixed Unicode list or a mixed latin1 list\n  InEncoding := {latin1 | unicode}\n</code></pre>\n\n<p>The word \"characters\" is used to denote a possibly complex\nrepresentation of characters in the encoding concerned, like a short\nword for \"a possibly mixed and deep list of characters and/or binaries\nin either latin1 representation or Unicode\".</p>\n\n<p>Giving latin1 as the encoding would mean that all of ML should be\ninterpreted as latin1 characters, implying that integers > 255 in the\nlist would be an error. Giving Unicode as the encoding would mean that\nall integers 0..16#10ffff are accepted and the binaries are expected\nto already be UTF-8 coded.</p>\n\n<p>In the same way, conversion to lists of Unicode characters could be done with a function::</p>\n\n<pre><code>unicode:characters_to_list(ML, InEncoding) -&gt; list() \n    ML := A mixed Unicode list or a mixed latin1 list\n    InEncoding := {latin1 | unicode}\n</code></pre>\n\n<p>I think the approach of two simple conversion functions\ncharacters<em>to</em>binary/2 and characters<em>to</em>list/2 is attractive, despite the fact\nthat certain combinations of in-data would be somewhat harder to\nconvert (e.g. combinations of Unicode characters > 255 in a list with\nbinaries in latin1). Extending the bit syntax to cope with UTF-8 would\nmake it easy to write special conversion functions to handle those\nrare situations where the above mentioned functions cannot do the job.</p>\n\n<p>To accommodate other encodings, the characters<em>to</em>binary functionality\ncould be extended to handle other encodings as well. A more general\nfunctionality could be provided with the following functions\n(preferably placed in their own module, the module name 'unicode'\nbeing a good name-candidate):</p>\n\n<p><strong>characters<em>to</em>binary(ML) -> binary() | {error, Encoded, Rest} | {incomplete, Encoded, Rest}</strong></p>\n\n<p>Same as characters<em>to</em>binary(ML,unicode,unicode).</p>\n\n<p><strong>characters<em>to</em>binary(ML,InEncoding) -> binary() | {error, Encoded, Rest} | {incomplete, Encoded, Rest}</strong></p>\n\n<p>Same as characters<em>to</em>binary(ML,InEncoding,unicode).</p>\n\n<p><strong>characters<em>to</em>binary(ML,InEncoding, OutEncoding) -> binary() | {error, Encoded, Rest} | {incomplete, Encoded, Rest}</strong></p>\n\n<p>Types:</p>\n\n<ul>\n<li>ML := A mixed list of integers or binaries corresponding to the\n    InEncoding or a binary in the InEncoding</li>\n<li>InEncoding := { latin1 | unicode | utf8 | utf16 | utf32 }</li>\n<li>OutEncoding := { latin1 | unicode | utf8 | utf16 | utf32 }</li>\n<li>Encoded := binary()</li>\n<li>Rest := Mixed list as specified for ML.</li>\n</ul>\n\n<p>The option 'unicode' is an alias for utf8, as this is the\npreferred encoding for Unicode characters in binaries. Error tuples\nare returned when the data cannot be encoded/decoded due to errors\nin indata and incomplete tuples when the indata is possibly correct\nbut truncated.</p>\n\n<p><strong>characters<em>to</em>list(ML) -> list() | {error, Encoded, Rest} | {incomplete, Encoded, Rest}</strong></p>\n\n<p>Same as characters<em>to</em>list(ML,unicode).</p>\n\n<p><strong>characters<em>to</em>list(ML,InEncoding) -> list() | {error, Encoded, Rest} | {incomplete, Encoded, Rest}</strong></p>\n\n<p>Types:  </p>\n\n<ul>\n<li>ML := A mixed list of integers or binaries corresponding to the\n    InEncoding or a binary in the InEncoding</li>\n<li>InEncoding := { latin1 | unicode | utf8 | utf16 | utf32 }</li>\n<li>Encoded := list()</li>\n<li>Rest := Mixed list as specified for ML.</li>\n</ul>\n\n<p>Here also the option 'unicode' denotes the default Erlang encoding\nof utf8 in binaries and is therefore an alias for utf8. Error- and\nincomplete-tuples are returned in the same way as for\ncharacters<em>to</em>binary.</p>\n\n<p>Note that as the datatypes returned upon success are well defined,\nguard tests exist (is<em>list/1 and is</em>binary/1), why i suggest not\nreturning the clunky {ok, Data} tuples even though the error and\nincomplete tuples can be returned. This makes the functions simpler to\nuse when the encoding is known to be correct while return values can\nstill be checked easily.</p>\n\n<h2>Bit syntax</h2>\n\n<p>Using Erlang bit syntax on binaries containing Unicode characters\nin UTF-8 could be facilitated by a new type. The type name utf8 would\nbe preferable to utf-8, as dashes (\"-\") have special meaning in bit\nsyntax separating type, signedness, endianess and units.</p>\n\n<p>The utf8 type in bit syntax matching would convert a UTF-8\ncoded character in the binary to an integer regardless of how many bytes it\noccupies, leaving the trailing part of the binary to be matched against the\nrest of the bit syntax matching expression.</p>\n\n<p>When constructing binaries, an integer converted to UTF-8 could\nconsequently occupy between one and four bytes in the resulting binary.</p>\n\n<p>As bit syntax is often used to interpret data from various external\nsources, it would be useful to have corresponding utf16 and utf32\ntypes as well. While UTF-8, UTF-16 and UTF-32 are easily interpreted\nwith the current bit syntax implementation, the suggested specific\ntypes would be convenient for the programmer. Also Unicode imposes\nrestrictions in terms of range and has some forbidden ranges which are best\nhandled using a built in bit syntax type.</p>\n\n<p>The utf16 and utf32 types need to have an endianess option, as UTF-16\nand UTF-32 can be stored as big or little endian entities.</p>\n\n<h2>Formatting functions</h2>\n\n<p>Given a default Unicode character representation in Erlang, let's dig\ndeeper into the formatting functions. I suggest the concept of\nformatting control sequence modifiers, an extra character between the\n\"~\" and the control character, denoting Unicode input/output. The\nletter \"t\" (for translate) is not used in any formatting functions\ntoday, making it a good candidate. The meaning of the modifier should\nbe such that e.g. the formatting control \"~ts\" means a string in\nUnicode while \"~s\" means means a string in iso-latin-1. The reason for not\nsimply introducing a new single control character, is that the\nsuggested modifier can be applicable to various control characters,\nlike e.g. \"p\" or even \"w\", while a new single control character for\nUnicode strings would only be a replacement for the current \"s\"\ncontrol character.</p>\n\n<p>Although the io-protocol in Erlang from the beginning did not impose\nany limit on what characters could be transferred between a client and\nan io_server, demands for better performance\nfrom the io-system in Erlang has made later\nimplementations use binaries for communication, which in practice has\nmade the io-protocol contain bytes, not general characters.</p>\n\n<p>Furthermore has the fact that the io-system currently works with\ncharacters that can be represented as bytes been utilized in numerous\napplications, so that output from io-functions (i.e. io<em>lib:format)\nhas been sent directly to entities only accepting byte input (like\nsockets) or that io</em>servers have been implemented assuming only\ncharacter ranges of 0 - 255. Of course this can be changed, but such a\nchange might include lower performance from the io-system as well as\nlarge changes to code already in production (aka \"customer code\").</p>\n\n<p>The io-system in Erlang currently works around an assumption that data\nis always a stream of bytes. Although this was not the original\nintention, this is how it's today used. This means that a latin1\nstring can be sent to a terminal or a file in much the same way, there\nwill never be any conversion needed. This might not always hold for\nterminals, but in case of terminals there is always one single\nconversion needed, namely that from the byte-stream to whatever the\nterminal likes. A disk-file is a stream of bytes as well as a terminal\nis, at least as far as the Erlang io-system is concerned. Furthermore\nthe io<em>lib formatting function always returns (possibly) deep lists of\nintegers, each representing one character, making it hard to\ndifferentiate between different encodings. The result is then sent as\nis by functions like io:format to the io</em>server where it is finally\nput on the disk. The servers also accept binaries, but they are never\nproduced by io_lib:format.</p>\n\n<p>When Erlang starts supporting Unicode characters, the world changes a\nlittle. A file might contain text in UTF-8 or in iso-latin-1 and there is\nno telling from the list produced by e.g io_lib:format\nwhat the user originally intended. </p>\n\n<p>Suggested solution\n...................</p>\n\n<p>To make a solution that as far as possible does not break current code\nand also keeps (or reverts to) the original intention of the io-system\nprotocol, I suggest a scheme where the formatting functions that\nreturn lists, keep to the current behavior as far as possible.</p>\n\n<p>So the io<em>lib:format function returns a (possibly deep) list of\nintegers 0..255 (latin1, which can be viewed as a subset of Unicode)\nif used without translation modifiers. If the translation modifiers\nare used, it will however return a possibly deep list of integers in\nthe complete unicode range. Going back to the Bulgarian string (ex1</em>),\nlet's look at the following::</p>\n\n<pre><code>1&gt; UniString = [1050,1072,1082,1074,\n            1086,32,1077,32,85,110,105,99,111,100,101,32,63].\n2&gt; io_lib:format(\"~s\",[UniString]).\n</code></pre>\n\n<p>- here the Unicode string violates the mixed latin1 list property and a\nbadarg exception will be raised. This behavior should be retained. On\nthe other hand::</p>\n\n<pre><code>3&gt; io_lib:format(\"~ts\",[UniString]).\n</code></pre>\n\n<p>- would return a (deep) list with the Unicode string as a list of integers::</p>\n\n<pre><code>[[1050,1072,1082,1074,1086,32,1077,32,85,110,105,99,111,100,\n  101,32,63]]\n</code></pre>\n\n<p>The downside of introducing integers > 255 in the result list is of course\nthat the return value of the function is no longer valid iodata(), but on\nthe other hand, the following code::</p>\n\n<pre><code>lists:flatten(io_lib:format(\"~ts\",[UniString]))\n</code></pre>\n\n<p>will give a result similar to that of a non-Unicode version. </p>\n\n<p>As the format modifier \"t\" is new, the possibility to get integers >\n255 in the resulting deep list will not break old code. To get\niodata() in UTF-8, one could simply do::</p>\n\n<pre><code>unicode:characters_to_binary(io_lib:format(\"~ts\",[UniString]),\n                             unicode, unicode)\n</code></pre>\n\n<p>As before, directly formatting (with ~s) a list of characters > 255\nwould be an error, but with the \"t\" modifier it would work.</p>\n\n<p>When it comes to range checking and backward compatibility::  </p>\n\n<pre><code>6&gt; io:format(File,\"~s\",[UniString]).\n</code></pre>\n\n<p>- would as before throw the badarg exception, while::</p>\n\n<pre><code>7&gt; io:format(File,\"~ts\",[UniString]).\n</code></pre>\n\n<p>- would be accepted. </p>\n\n<p>The corresponding behavior of io:fread/2,3 would be to expect Unicode data in this call::</p>\n\n<pre><code>11&gt; io:fread(File,'',\"~ts\").\n</code></pre>\n\n<p>- but expect latin1 in this::</p>\n\n<pre><code>12&gt; io:fread(File,'',\"~s\").\n</code></pre>\n\n<p>The actual io-protocol, on the other hand, should deal only with\nUnicode, meaning that when data is converted to binaries for sending,\nall data should be translated into UTF-8. When lists of integers are\nused in communication, the latin1 and Unicode representations are the\nsame, why no conversion or restrictions apply. Recall that the\nio-system is built so that characters should have one interpretation\nregardless of the io-server. The only possible encoding would be a\nUnicode one.</p>\n\n<p>As we are communicating heavily between processes (the client and\nserver processes in the io-system), converting the data to Unicode\nbinaries (UTF-8) is the most efficient strategy for larger amounts of\ndata.</p>\n\n<p>Generally, writing\nto an io-server using the file-module will only be possible with\nbyte-oriented data, while using the io-module will work on Unicode\ncharacters. Calling the function file\\:write/2 will send the bytes to\nthe file as is, as files are byte-oriented, but when writing on a file\nusing the io-module, Unicode characters are expected and handled.</p>\n\n<p>The io-protocol will make conversions of bytes into Unicode when\nsending to io-servers, but if the file is byte-oriented, the\nconversion back will make this transparent to the user. All bytes are\nrepresentable in UTF-8 and can be converted back and forth without hassle.</p>\n\n<p>The incompatible change will have to be to the put_chars function in\nio. It should only allow Unicode data, not iodata() as it is\ndocumented to do now. The big change being that any binaries provided\nto the function need to be in UTF-8. However, most usage of this\nfunction is restricted to lists, why this incompatible change is\nexpected not to cause trouble for users.</p>\n\n<p>To handle possible Unicode text data on a file, one should be able to\nprovide encoding parameters when opening a file. A file should by\ndefault be opened for byte (or latin1) encoding, while the option to\nopen it for i.e. utf8 translation should be available.</p>\n\n<p>Lets look at some examples:</p>\n\n<p>Example 1 - common byte-oriented writing\n........................................</p>\n\n<p>A file is opened as usual with file\\:open. We then want to write bytes\nto it:</p>\n\n<ul>\n<li><p>Using file\\:write with iodata() (bytes), the data is converted into\nUTF-8 by the io-protocol, but the io-server will convert it back to\nlatin1 before actually putting the bytes on file. For better\nperformance, the file could be opened in raw mode, avoiding all\nconversion.</p></li>\n<li><p>Using file\\:write with data already converted to UTF-8 by the user,\nthe io-protocol will embed this in yet another layer of UTF-8\nencoding, the file-server will unpack it and we will end up with the\nUTF-8 bytes written to the file as expected.</p></li>\n<li><p>Using io:put<em>chars, the io-server will return an error if any of the\nUnicode characters sent are not possible to represent in one\nbyte. Characters representable in latin1 will however be written\nnicely even though they might be encoded as UTF-8 in binaries sent\nto io:put</em>chars. As long as the io<em>lib:format function is used\nwithout the translation-modifier, everything will be valid latin1\nand all return values will be lists, why it is both valid Unicode *and*\npossible to write on a default file. Old code will function as\nbefore, except when feeding io:put</em>chars with latin1 binaries, in\nthat case the call should be replaced with a file\\:write call.</p></li>\n</ul>\n\n<p>Example 2 - Unicode-oriented writing\n....................................</p>\n\n<p>A file is opened using a parameter telling that Unicode data should be\nwritten in a defined encoding, in this case we'll select UTF-16/bigendian to\navoid mix-ups with the native UTF-8 encoding. We open the file with\nfile\\:open(Name,[write,{encoding,utf16,bigendian}]). </p>\n\n<ul>\n<li><p>Using file\\:write with iodata(), the io-protocol will convert into\nthe default Unicode representation (UTF-8) and send the data to the\nio-server, which will in turn convert the data to UTF-16 and put it\non the file. The file is to be regarded as a text file and all\niodata() sent to it will be regarded as text.</p></li>\n<li><p>If the data is already in Unicode representation (say UTF-8) it\nshould not be written to this type of file using file\\:write,\nio:put_chars is expected to be used (which is not a problem as\nUnicode data should not exist in old code and this is only a problem\nwhen the file is opened to translate).</p></li>\n<li><p>If the data is in the Erlang default Unicode format, it can be\nwritten to the file using io:put<em>chars. This works for all types of\nlists with integers and for binaries in UTF-8, for other\nrepresentations (most notably latin1 in binaries) the data should be\nconverted using Unicode:characters</em>to_XXX(Data,latin1) prior to\nsending. For latin1 mixed lists (iodata()), file\\:write can also be\nused directly.</p></li>\n</ul>\n\n<p>To sum up this case - Unicode strings (including latin1 lists) are\nwritten to a converting file using io:put_chars, but pure iodata() can\nalso be implicitly converted to the encoding by using file\\:write.</p>\n\n<p>Example 3 - raw writing\n.......................</p>\n\n<p>A file opened for raw access will only handle bytes, it cannot be used\ntogether with io:put_chars.</p>\n\n<ul>\n<li><p>Data formatted with io<em>lib:format can still be written to a raw file\nusing file\\:write. The data will end up being written as is. If the\ntranslation modifier is consistently used when formatting, the file\nwill get the native UTF-8 encoding, if no translation modifiers are\nused, the file will have latin1 encoding (each character in the list\nreturned from io</em>lib:format will be representable as a latin1\nbyte). If data is generated in different ways, the conversion\nfunctions will have to be used.</p></li>\n<li><p>Data written with file\\:write will be put on the file directly, no\nconversion to and from Unicode representation will happen.</p></li>\n</ul>\n\n<p>Example 4 - byte-oriented reading\n.................................</p>\n\n<p>When a file is opened for reading, much the same things apply as for\nwriting.</p>\n\n<ul>\n<li><p>file\\:read on any file will expect the io-protocol to deliver data as\nUnicode. Each byte will be converted to Unicode by the io_server and\nturned back to a byte by file\\:read</p></li>\n<li><p>If the file actually contains Unicode characters, they will be byte-wise\nconverted to Unicode and then back, giving file\\:read the\noriginal encoding. If read as (or converted to) binaries they can\nthen easily be converted back to the Erlang default representation\nby means of the conversion routines.</p></li>\n<li><p>If the file is read with io:get<em>chars, all characters will be\nreturned in a list as expected. All characters will be latin1, but\nthat is a subset of Unicode and there will be no difference to\nreading a translating file. If the file however contains Unicode\nconverted characters and is read in this way, the return value from\nio:get</em>chars will be hard to interpret, but that is to be\nexpected. If such a functionality is desired, the list can be\nconverted to a binary with list<em>to</em>binary and then explored as a\nUnicode entity in the encoding the file actually has.</p></li>\n</ul>\n\n<p>Example 5 - Unicode file reading\n................................</p>\n\n<p>As when writing, reading Unicode converting files is best done with\nthe io-module. Let's once again assume UTF-16 on the file.</p>\n\n<ul>\n<li><p>When reading using file\\:read, the UTF-16 data will be converted into\na Unicode representation native to Erlang and sent to the\nclient. If the client is using file\\:read, it will translate the data\nback to bytes in the same way as bytes were translated to Unicode\nfor the protocol when writing. Is everything representable as bytes,\nthe function will succeed, but if any Unicode character larger than\n255 is present, the function will fail with a decoding error.</p></li>\n<li><p>Unicode data in the range over code-point 255 can not be retrieved by\nuse of the file-module. The io-module should be used instead.</p></li>\n<li><p>io:get<em>chars and io:get</em>line will work on the Unicode data provided\nby the io-protocol. All Unicode returns will be as Unicode lists as\nexpected. The fread function will return lists with integers > 255 only\nwhen the translation modifier is supplied.</p></li>\n</ul>\n\n<p>Example 6 - raw reading\n.......................</p>\n\n<p>As with writing, only the file module can be used and only byte\noriented data is read. If encoded, the encoding will remain when\nreading and writing raw files.</p>\n\n<p>Conclusions from the examples\n.............................</p>\n\n<p>With this solution, the file module is consistent with latin1\nio<em>servers (aka common files) and raw files. A file type, a translating\nfile, is added for the io-module to be able to get implicit conversion\nof its Unicode data (another example of such an io</em>server with\nimplicit conversion would of course be the\nterminal). Interface-wise,common files behave as before and we only\nget added functionality. </p>\n\n<p>The downsides are the subtly changed behavior of io:put_chars and the\nperformance impact by the conversion to and from Unicode\nrepresentations when using the file module on non-raw files with\ndefault (latin1/byte) encoding. The latter may be possible to change\nby extending the io-protocol to tag whole chunks of data as bytes\n(latin1) or Unicode, but using raw files for writing large amounts of\ndata is often the better solution in those cases.</p>\n\n<h1>Specification</h1>\n\n<h2>Convention</h2>\n\n<p>I suggest the convention of letting the Unicode representation in\nlists be one character per element, in binaries UTF-8 and in mixed\nUnicode entities a combination of those.</p>\n\n<h2>Conversion to and from latin1 and UTF-8</h2>\n\n<p>I also suggest a module 'unicode', containing functions for\nconverting between representations of Unicode. The default format for\nall functions should be utf8 in binaries to point out this as the\npreferred internal representation of Unicode characters in binaries. </p>\n\n<p>The two main conversion functions should be characters<em>to</em>binary/3 and\ncharacters<em>to</em>list/2 as described above.</p>\n\n<h2>Bit syntax</h2>\n\n<p>I suggest an extension to the bit syntax, allowing matching and\nconstruction in UTF-8 coding, e.g::</p>\n\n<pre><code>&lt;&lt;Ch/utf8,_/binary&gt;&gt; = BinString\n</code></pre>\n\n<p>as well as::</p>\n\n<pre><code>MyBin = &lt;&lt;Ch/utf8,More/binary&gt;&gt;\n</code></pre>\n\n<p>Optionally UTF-16 could be supported in a similar way for binaries, e.g::</p>\n\n<pre><code>&lt;&lt;Ch/utf16-little,_/binary&gt;&gt; = BinString\n</code></pre>\n\n<p>UTF-32 will need to be supported in a similar way as UTF-16, both for\ncompleteness and for the range-checking that will be involved when\nconverting Unicode characters.</p>\n\n<h2>Formatting</h2>\n\n<p>I finally suggest the \"t\" modifier to control sequence in the\nformatting function, which expects mixed lists of integers\n0..16#10ffff and binaries with UTF-8 coded Unicode characters. The\nfunctions in  io and io_lib will retain their current\nfunctionality for code not using the translation modifier, but will\nreturn Unicode characters when ordered to.  </p>\n\n<p>The fread function should in the same way accept Unicode data only\nwhen the \"t\" modifier is used.</p>\n\n<p>The io-protocol need to be changed to always handle Unicode characters.\nOptions given when opening a file will allow for implicit conversion of\ntext files.</p>\n\n<h1>Copyright</h1>\n\n<p>This document has been placed in the public domain.</p>\n"}},"__N_SSG":true}