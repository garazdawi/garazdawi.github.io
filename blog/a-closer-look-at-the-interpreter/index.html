<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>Erlang Programming Language</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta name="description" content="Erlang Programming Language"/><meta name="keywords" content="erlang, functional, programming, fault-tolerant, distributed, multi-platform, portable, software, multi-core, smp, concurrency"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><link rel="alternate" type="application/rss+xml" title="Overall RSS 2.0 Feed" href="/rss"/><link rel="alternate" type="application/rss+xml" title="News RSS 2.0 Feed" href="/rss/news"/><link rel="alternate" type="application/rss+xml" title="Article RSS 2.0 Feed" href="/rss/articles"/><link rel="alternate" type="application/rss+xml" title="Events RSS 2.0 Feed" href="/rss/event"/><link rel="alternate" type="application/rss+xml" title="Downloads RSS 2.0 Feed" href="/rss/download"/><script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/css/f91c265ba4ec340e076d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f91c265ba4ec340e076d.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-a9a86200c2afaf3f233a.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.9707fddd9ae5927c17c3.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.8b4ad2366e12f882e3d5.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-79f3144d8877c67ce98b.js" as="script"/><link rel="preload" href="/_next/static/chunks/9f96d65d.6d2fb2f6923d41a412a8.js" as="script"/><link rel="preload" href="/_next/static/chunks/87b308f4a72b1b263da2fe072492c20d1199252a.8368050723e578161621.js" as="script"/><link rel="preload" href="/_next/static/chunks/2968c2e854f156f56dcf4f3a0f05db49ee39d399.938502fc97c89e1a18f7.js" as="script"/><link rel="preload" href="/_next/static/chunks/a9595808cf5ee3285d96b2a14ee913304b9362ca.20c663042d024f8cc93c.js" as="script"/><link rel="preload" href="/_next/static/chunks/202314b546da1167b19f69946a64c65ef91ce335.8b78b06e27cf5f3f1fd9.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/blog/%5Bblog%5D-68965b4ff10aaca11026.js" as="script"/></head><body><div id="__next"><div class="navbar" style="background-color:#FFF;margin-bottom:0px"><div class="container"><button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse" style="position:absolute;right:5px;margin-bottom:0px"><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand" href="/"><img src="/img/erlang.png" width="60"/></a><div class="nav-collapse collapse navbar-responsive-collapse" style="padding:20px"><ul class="nav navbar-nav"><li><a class="menu-headlines" href="/downloads/"> DOWNLOADS </a></li><li><a class="menu-headlines" href="/docs/"> DOCUMENTATION </a></li><li><a class="menu-headlines" href="/community/"> COMMUNITY </a></li><li><a class="menu-headlines" href="/news/"> NEWS </a></li><li><a class="menu-headlines" href="/eeps/"> EEPS </a></li><li><a class="menu-headlines" href="/blog/"> BLOG </a></li><li><a class="menu-headlines" href="/about/"> ABOUT </a></li></ul></div></div></div><div class="container"><div class="row"><div class="col-lg-12"><div class="divider"><p></p></div></div><div class="col-lg-12"><h3 class="sub-headlines"><img src="/img/news.png"/><span style="position:relative;top:5px;left:20px">NEWS</span></h3></div><div class="col-lg-2"><p></p></div><div class="col-lg-8"><div class="inside-cols"><h3><a href="/blog/a-closer-look-at-the-interpreter/">A closer look at the interpreter</a></h3><p><em>Tuesday, 27 October 2020<!-- --> - <!-- -->John HÃ¶gberg</em></p><p>In my <a href="http://blog.erlang.org/a-brief-BEAM-primer/">previous post</a> we had a look at BEAM, and now that we&#x27;re more familiar
with it it&#x27;s time for us to look at the reference implementation: the
interpreter.</p><p>The interpreter can be thought of as an endless loop that looks at the current
instruction, executes it, and then moves on to the next one.</p><p>In normal builds our code is laid out as <a href="https://en.wikipedia.org/wiki/Threaded_code">directly threaded code</a>, where each
instruction consists of the <em>machine code address</em> of its handler, followed by
its arguments, which are in turn followed by the next instruction:</p><pre><code>Instruction address
    First argument
    Second argument
    ... and so on.
Instruction address
    First argument
    Second argument
    ... and so on.</code></pre><p>When an instruction finishes it reads the next instruction address and jumps
to it, forever following the &quot;thread&quot; of instructions.</p><p>With very few exceptions, the instructions are &quot;pure&quot; in the sense that they
always do the same thing with the same input and that they only affect BEAM,
either through changing the control flow or writing a result to a register.
This makes the instructions very easy to read and reason about in isolation, so
for the sake of brevity we&#x27;ll only have a look at one of them:</p><pre><code class="language-c++">is_nonempty_list(Label, Src) {

    /* Check if our $Src is not a list. */
    if (is_not_list($Src)) {

        /* Invoke the $FAIL macro, jumping to our
         * $Label. */
        $FAIL($Label);
    }

    /* Execute the next instruction. */
}</code></pre><p>The above is written in a domain-specific language (DSL) that is a superset of
C, where <code>$</code>-prefixed macros are expanded and the rest is kept as is.</p><p>The <a href="https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/utils/beam_makeops"><code>beam_makeops</code></a> script takes this definition and generates code for
the parts that are cumbersome to write by hand, such as jumping to the next
instruction. It also hides argument handling which allows us to reduce the code
size by packing small arguments together behind the scenes, which we&#x27;ve
explored in an <a href="http://blog.erlang.org/Interpreter-Optimizations/">earlier post</a> on the subject.</p><p>For performance reasons it also generates different variants based on the
argument types outlined in <a href="https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/ops.tab"><code>ops.tab</code></a> to reduce the amount of work we need to
do at runtime.</p><p>Let&#x27;s have a look at the generated code for this instruction, specifically the
variant for <code>X</code> registers:</p><pre><code class="language-c++">/* (This has been modified slightly for readability) */
case is_nonempty_list_fx:
{
    Eterm arg_word, term;

    /* Read the argument word from the instruction
     * stream. */
    arg_word = I[1];

    /* Unpack the offset of our source register (upper
     * 32 bits) and then read its contents.
     *
     * Note that we address the X registers directly;
     * had this instruction not been specialized, we
     * would first need to determine whether the
     * argument was an X or a Y register. */
    term = x_registers[arg_word &gt;&gt; 32];

    /* is_not_list(term) */
    if (term &amp; (_TAG_PRIMARY_MASK - TAG_PRIMARY_LIST)) {

        /* Unpack our fail label (lower 32 bits) and add
         * it to our current instruction pointer. This
         * is an offset and may be negative for backward
         * jumps. */
        I += (Sint32)arg_word;

        /* Jump to the instruction at the fail label using
         * the &quot;labels as values&quot; GCC extension. */
        goto *I;
    }

    /* Skip the current label address and argument word,
     * then jump to the next instruction. This was
     * automatically generated by beam_makeops. */
    I += 2;
    goto *I;
}</code></pre><p>There&#x27;s a bit more to it, and those who would like to know more can read the
<a href="http://erlang.org/doc/apps/erts/beam_makeops.html">documentation for the <code>beam_makeops</code> script</a>, but the above covers the gist of
it.</p><p>While the above is quite efficient, there&#x27;s significant overhead from dispatch
and argument handling. Here&#x27;s a slightly altered assembly listing of the
above:</p>&lt;pre class=&quot;highlight&quot;&gt;
    &lt;em&gt;; Read the argument word from the instruction
    ; stream.&lt;/em&gt;
    mov    rdx, [rbx + 8]

    &lt;em&gt;; Unpack the offset of our source register (upper 32
    ; 32 bits).&lt;/em&gt;
    mov    rcx, rdx
    shr    rcx, 32

    &lt;em&gt;; X registers live in machine register r15, and we
    ; placed our offset in rcx, so we can find our term at
    ; [r15 + rcx].
    ;
    ; Perform a non-destructive bitwise AND on the term
    ; using the `test` instruction, and jump to the fail
    ; label if the result is non-zero.&lt;/em&gt;
    &lt;b&gt;test   byte [r15 + rcx], (_TAG_PRIMARY_MASK - TAG_PRIMARY_LIST)
    jne    jump_to_fail_label&lt;/b&gt;

    &lt;em&gt;; Skip the current label address and argument word,
    ; then jump to the next instruction.&lt;/em&gt;
    add    rbx, 16
    jmp    [rbx]

jump_to_fail_label:
    &lt;em&gt;; Unpack our fail label (lower 32 bits) and add
    ; it to our current instruction pointer.&lt;/em&gt;
    movsxd rdx, edx
    lea    rbx, [rbx + rdx * 8]

    &lt;em&gt;; Jump to the instruction at the fail label.&lt;/em&gt;
    jmp    [rbx]
&lt;/pre&gt;<p>The bold section is the meat of the instruction and the rest is argument
unpacking and instruction dispatch. While this is not much of a problem for
large instructions, its effect on short ones like this is very large, and when
looking through a profiler (e.g. <a href="https://en.wikipedia.org/wiki/Perf_%28Linux%29"><code>perf</code></a>) it&#x27;s not unusual for the final <code>jmp</code>
to dominate the rest.</p><p>To lessen this effect, the loader combines commonly used instruction sequences
into a single instruction. For example, two independent moves may fuse into
<a href="https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L577"><code>move2_par</code></a>, and <code>is_nonempty_list</code> followed by <code>get_list</code> might be fused to
<a href="https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L795"><code>is_nonempty_list_get_list</code></a>.</p><p>This reduces the cost of short instructions, but only works to the extent we&#x27;re
able to identify common patterns and comes at a significant maintenance cost
as each combination must be implemented manually. Even so, the effect tends to
be moderate and the dispatch overhead remains significant.</p><p>Another, albeit lesser, downside with the interpreter is that modern processors
are very optimized for patterns commonly found in &quot;ordinary&quot; native code. For
example, nearly all of them have a special branch predictor just for calls and
returns. Assuming that every call has a corresponding return lets it predict
returns <em>perfectly</em> unless an exception is thrown, but since the interpreter
does not use native calls and returns, it cannot make use of this optimization.</p><p>Unfortunately there&#x27;s not a whole lot that can be done about this, and after
over two decades of refinement it&#x27;s becoming increasingly difficult to optimize
it in meaningful ways.</p><p>Because of that our quest to improve performance has instead focused on two
areas: improving the compiler and implementing a JIT. We&#x27;ve made great strides
with both as of late, and are very proud to have finally merged the latter.</p><p>Stay tuned for our next post, where we&#x27;ll have a look at the JIT and see how it
avoids these issues.</p></div></div><div class="col-lg-2"><p><a href="/rss/blog/"><img src="/img/rss-icon.png" width="64"/></a></p></div></div></div><div class="container"><div class="row"><div class="col-lg-12"><div class="divider"><p></p></div></div><div class="col-lg-12 text-center"><div class="col-lg-4"><a title="DOWNLOAD" href="/download.html"><img src="/img/download.png"/></a></div><div class="col-lg-4"><a href="http://www.github.com/erlang/otp/"><img src="/img/GitHub-Mark-32px.png"/></a></div><div class="col-lg-4"><a href="http://www.twitter.com/erlang_org/"><img src="/img/twitter.png" width="32"/></a></div></div><div class="col-lg-12"><div class="divider"><p></p></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"item":{"id":"a-closer-look-at-the-interpreter","title":"A closer look at the interpreter","author":"John HÃ¶gberg","excerpt":"\nIn my [previous post] we had a look at BEAM, and now that we're more familiar\nwith it it's time for us to look at the reference implementation: the\ninterpreter.\n\n[directly threaded code]: https://en.wikipedia.org/wiki/Threaded_code,\n[`ops.tab`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/ops.tab,\n[`beam_makeops`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/utils/beam_makeops,\n[documentation for the `beam_makeops` script]: http://erlang.org/doc/apps/erts/beam_makeops.html,\n[`move2_par`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L577,\n[`is_nonempty_list_get_list`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L795,\n[`perf`]: https://en.wikipedia.org/wiki/Perf_%28Linux%29,\n[earlier post]: http://blog.erlang.org/Interpreter-Optimizations/,\n[previous post]: http://blog.erlang.org/a-brief-BEAM-primer/","article_date":1603756800000,"tags":["BEAM","erts","jit"],"frontmatter":{"layout":"post","title":"A closer look at the interpreter","tags":"BEAM erts jit","author":"John HÃ¶gberg"},"content":"\nIn my [previous post] we had a look at BEAM, and now that we're more familiar\nwith it it's time for us to look at the reference implementation: the\ninterpreter.\n\nThe interpreter can be thought of as an endless loop that looks at the current\ninstruction, executes it, and then moves on to the next one.\n\nIn normal builds our code is laid out as [directly threaded code], where each\ninstruction consists of the _machine code address_ of its handler, followed by\nits arguments, which are in turn followed by the next instruction:\n\n    Instruction address\n        First argument\n        Second argument\n        ... and so on.\n    Instruction address\n        First argument\n        Second argument\n        ... and so on.\n\nWhen an instruction finishes it reads the next instruction address and jumps\nto it, forever following the \"thread\" of instructions.\n\nWith very few exceptions, the instructions are \"pure\" in the sense that they\nalways do the same thing with the same input and that they only affect BEAM,\neither through changing the control flow or writing a result to a register.\nThis makes the instructions very easy to read and reason about in isolation, so\nfor the sake of brevity we'll only have a look at one of them:\n\n```c++\nis_nonempty_list(Label, Src) {\n\n    /* Check if our $Src is not a list. */\n    if (is_not_list($Src)) {\n\n        /* Invoke the $FAIL macro, jumping to our\n         * $Label. */\n        $FAIL($Label);\n    }\n\n    /* Execute the next instruction. */\n}\n```\n\nThe above is written in a domain-specific language (DSL) that is a superset of\nC, where `$`-prefixed macros are expanded and the rest is kept as is.\n\nThe [`beam_makeops`] script takes this definition and generates code for\nthe parts that are cumbersome to write by hand, such as jumping to the next\ninstruction. It also hides argument handling which allows us to reduce the code\nsize by packing small arguments together behind the scenes, which we've\nexplored in an [earlier post] on the subject.\n\nFor performance reasons it also generates different variants based on the\nargument types outlined in [`ops.tab`] to reduce the amount of work we need to\ndo at runtime.\n\nLet's have a look at the generated code for this instruction, specifically the\nvariant for `X` registers:\n\n```c++\n/* (This has been modified slightly for readability) */\ncase is_nonempty_list_fx:\n{\n    Eterm arg_word, term;\n\n    /* Read the argument word from the instruction\n     * stream. */\n    arg_word = I[1];\n\n    /* Unpack the offset of our source register (upper\n     * 32 bits) and then read its contents.\n     *\n     * Note that we address the X registers directly;\n     * had this instruction not been specialized, we\n     * would first need to determine whether the\n     * argument was an X or a Y register. */\n    term = x_registers[arg_word \u003e\u003e 32];\n\n    /* is_not_list(term) */\n    if (term \u0026 (_TAG_PRIMARY_MASK - TAG_PRIMARY_LIST)) {\n\n        /* Unpack our fail label (lower 32 bits) and add\n         * it to our current instruction pointer. This\n         * is an offset and may be negative for backward\n         * jumps. */\n        I += (Sint32)arg_word;\n\n        /* Jump to the instruction at the fail label using\n         * the \"labels as values\" GCC extension. */\n        goto *I;\n    }\n\n    /* Skip the current label address and argument word,\n     * then jump to the next instruction. This was\n     * automatically generated by beam_makeops. */\n    I += 2;\n    goto *I;\n}\n```\n\nThere's a bit more to it, and those who would like to know more can read the\n[documentation for the `beam_makeops` script], but the above covers the gist of\nit.\n\nWhile the above is quite efficient, there's significant overhead from dispatch\nand argument handling. Here's a slightly altered assembly listing of the\nabove:\n\n\u003cpre class=\"highlight\"\u003e\n    \u003cem\u003e; Read the argument word from the instruction\n    ; stream.\u003c/em\u003e\n    mov    rdx, [rbx + 8]\n\n    \u003cem\u003e; Unpack the offset of our source register (upper 32\n    ; 32 bits).\u003c/em\u003e\n    mov    rcx, rdx\n    shr    rcx, 32\n\n    \u003cem\u003e; X registers live in machine register r15, and we\n    ; placed our offset in rcx, so we can find our term at\n    ; [r15 + rcx].\n    ;\n    ; Perform a non-destructive bitwise AND on the term\n    ; using the `test` instruction, and jump to the fail\n    ; label if the result is non-zero.\u003c/em\u003e\n    \u003cb\u003etest   byte [r15 + rcx], (_TAG_PRIMARY_MASK - TAG_PRIMARY_LIST)\n    jne    jump_to_fail_label\u003c/b\u003e\n\n    \u003cem\u003e; Skip the current label address and argument word,\n    ; then jump to the next instruction.\u003c/em\u003e\n    add    rbx, 16\n    jmp    [rbx]\n\njump_to_fail_label:\n    \u003cem\u003e; Unpack our fail label (lower 32 bits) and add\n    ; it to our current instruction pointer.\u003c/em\u003e\n    movsxd rdx, edx\n    lea    rbx, [rbx + rdx * 8]\n\n    \u003cem\u003e; Jump to the instruction at the fail label.\u003c/em\u003e\n    jmp    [rbx]\n\u003c/pre\u003e\n\nThe bold section is the meat of the instruction and the rest is argument\nunpacking and instruction dispatch. While this is not much of a problem for\nlarge instructions, its effect on short ones like this is very large, and when\nlooking through a profiler (e.g. [`perf`]) it's not unusual for the final `jmp`\nto dominate the rest.\n\nTo lessen this effect, the loader combines commonly used instruction sequences\ninto a single instruction. For example, two independent moves may fuse into\n[`move2_par`], and `is_nonempty_list` followed by `get_list` might be fused to\n[`is_nonempty_list_get_list`].\n\nThis reduces the cost of short instructions, but only works to the extent we're\nable to identify common patterns and comes at a significant maintenance cost\nas each combination must be implemented manually. Even so, the effect tends to\nbe moderate and the dispatch overhead remains significant.\n\nAnother, albeit lesser, downside with the interpreter is that modern processors\nare very optimized for patterns commonly found in \"ordinary\" native code. For\nexample, nearly all of them have a special branch predictor just for calls and\nreturns. Assuming that every call has a corresponding return lets it predict\nreturns _perfectly_ unless an exception is thrown, but since the interpreter\ndoes not use native calls and returns, it cannot make use of this optimization.\n\nUnfortunately there's not a whole lot that can be done about this, and after\nover two decades of refinement it's becoming increasingly difficult to optimize\nit in meaningful ways.\n\nBecause of that our quest to improve performance has instead focused on two\nareas: improving the compiler and implementing a JIT. We've made great strides\nwith both as of late, and are very proud to have finally merged the latter.\n\nStay tuned for our next post, where we'll have a look at the JIT and see how it\navoids these issues.\n\n[directly threaded code]: https://en.wikipedia.org/wiki/Threaded_code\n[`ops.tab`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/ops.tab\n[`beam_makeops`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/utils/beam_makeops\n[documentation for the `beam_makeops` script]: http://erlang.org/doc/apps/erts/beam_makeops.html\n[`move2_par`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L577\n[`is_nonempty_list_get_list`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L795\n[`perf`]: https://en.wikipedia.org/wiki/Perf_%28Linux%29\n[earlier post]: http://blog.erlang.org/Interpreter-Optimizations/\n[previous post]: http://blog.erlang.org/a-brief-BEAM-primer/\n"}},"__N_SSG":true},"page":"/blog/[blog]","query":{"blog":"a-closer-look-at-the-interpreter"},"buildId":"In61zFhZNXGgIV-idPSaW","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"charSet":"utf-8"}],["title",{"children":"Erlang Programming Language"}],["meta",{"httpEquiv":"Content-Type","content":"text/html;charset=utf-8"}],["meta",{"name":"description","content":"Erlang Programming Language"}],["meta",{"name":"keywords","content":"erlang, functional, programming, fault-tolerant, distributed, multi-platform, portable, software, multi-core, smp, concurrency"}],["meta",{"name":"viewport","content":"width=device-width, initial-scale=1.0"}],["link",{"rel":"alternate","type":"application/rss+xml","title":"Overall RSS 2.0 Feed","href":"/rss"}],["link",{"rel":"alternate","type":"application/rss+xml","title":"News RSS 2.0 Feed","href":"/rss/news"}],["link",{"rel":"alternate","type":"application/rss+xml","title":"Article RSS 2.0 Feed","href":"/rss/articles"}],["link",{"rel":"alternate","type":"application/rss+xml","title":"Events RSS 2.0 Feed","href":"/rss/event"}],["link",{"rel":"alternate","type":"application/rss+xml","title":"Downloads RSS 2.0 Feed","href":"/rss/download"}],["script",{"src":"https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"}],["script",{"src":"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js","integrity":"sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa","crossOrigin":"anonymous"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-8bebc7aacc0076174a73.js"></script><script src="/_next/static/chunks/main-a9a86200c2afaf3f233a.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.9707fddd9ae5927c17c3.js" async=""></script><script src="/_next/static/chunks/commons.8b4ad2366e12f882e3d5.js" async=""></script><script src="/_next/static/chunks/pages/_app-79f3144d8877c67ce98b.js" async=""></script><script src="/_next/static/chunks/9f96d65d.6d2fb2f6923d41a412a8.js" async=""></script><script src="/_next/static/chunks/87b308f4a72b1b263da2fe072492c20d1199252a.8368050723e578161621.js" async=""></script><script src="/_next/static/chunks/2968c2e854f156f56dcf4f3a0f05db49ee39d399.938502fc97c89e1a18f7.js" async=""></script><script src="/_next/static/chunks/a9595808cf5ee3285d96b2a14ee913304b9362ca.20c663042d024f8cc93c.js" async=""></script><script src="/_next/static/chunks/202314b546da1167b19f69946a64c65ef91ce335.8b78b06e27cf5f3f1fd9.js" async=""></script><script src="/_next/static/chunks/pages/blog/%5Bblog%5D-68965b4ff10aaca11026.js" async=""></script><script src="/_next/static/In61zFhZNXGgIV-idPSaW/_buildManifest.js" async=""></script><script src="/_next/static/In61zFhZNXGgIV-idPSaW/_ssgManifest.js" async=""></script></body></html>