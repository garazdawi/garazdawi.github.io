{"pageProps":{"item":{"id":"a-closer-look-at-the-interpreter","title":"A closer look at the interpreter","author":"John Högberg","excerpt":"\nIn my [previous post] we had a look at BEAM, and now that we're more familiar\nwith it it's time for us to look at the reference implementation: the\ninterpreter.\n\n[directly threaded code]: https://en.wikipedia.org/wiki/Threaded_code,\n[`ops.tab`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/ops.tab,\n[`beam_makeops`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/utils/beam_makeops,\n[documentation for the `beam_makeops` script]: http://erlang.org/doc/apps/erts/beam_makeops.html,\n[`move2_par`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L577,\n[`is_nonempty_list_get_list`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L795,\n[`perf`]: https://en.wikipedia.org/wiki/Perf_%28Linux%29,\n[earlier post]: http://blog.erlang.org/Interpreter-Optimizations/,\n[previous post]: http://blog.erlang.org/a-brief-BEAM-primer/","article_date":1603756800000,"tags":["BEAM","erts","jit"],"frontmatter":{"layout":"post","title":"A closer look at the interpreter","tags":"BEAM erts jit","author":"John Högberg"},"content":"\nIn my [previous post] we had a look at BEAM, and now that we're more familiar\nwith it it's time for us to look at the reference implementation: the\ninterpreter.\n\nThe interpreter can be thought of as an endless loop that looks at the current\ninstruction, executes it, and then moves on to the next one.\n\nIn normal builds our code is laid out as [directly threaded code], where each\ninstruction consists of the _machine code address_ of its handler, followed by\nits arguments, which are in turn followed by the next instruction:\n\n    Instruction address\n        First argument\n        Second argument\n        ... and so on.\n    Instruction address\n        First argument\n        Second argument\n        ... and so on.\n\nWhen an instruction finishes it reads the next instruction address and jumps\nto it, forever following the \"thread\" of instructions.\n\nWith very few exceptions, the instructions are \"pure\" in the sense that they\nalways do the same thing with the same input and that they only affect BEAM,\neither through changing the control flow or writing a result to a register.\nThis makes the instructions very easy to read and reason about in isolation, so\nfor the sake of brevity we'll only have a look at one of them:\n\n```c++\nis_nonempty_list(Label, Src) {\n\n    /* Check if our $Src is not a list. */\n    if (is_not_list($Src)) {\n\n        /* Invoke the $FAIL macro, jumping to our\n         * $Label. */\n        $FAIL($Label);\n    }\n\n    /* Execute the next instruction. */\n}\n```\n\nThe above is written in a domain-specific language (DSL) that is a superset of\nC, where `$`-prefixed macros are expanded and the rest is kept as is.\n\nThe [`beam_makeops`] script takes this definition and generates code for\nthe parts that are cumbersome to write by hand, such as jumping to the next\ninstruction. It also hides argument handling which allows us to reduce the code\nsize by packing small arguments together behind the scenes, which we've\nexplored in an [earlier post] on the subject.\n\nFor performance reasons it also generates different variants based on the\nargument types outlined in [`ops.tab`] to reduce the amount of work we need to\ndo at runtime.\n\nLet's have a look at the generated code for this instruction, specifically the\nvariant for `X` registers:\n\n```c++\n/* (This has been modified slightly for readability) */\ncase is_nonempty_list_fx:\n{\n    Eterm arg_word, term;\n\n    /* Read the argument word from the instruction\n     * stream. */\n    arg_word = I[1];\n\n    /* Unpack the offset of our source register (upper\n     * 32 bits) and then read its contents.\n     *\n     * Note that we address the X registers directly;\n     * had this instruction not been specialized, we\n     * would first need to determine whether the\n     * argument was an X or a Y register. */\n    term = x_registers[arg_word >> 32];\n\n    /* is_not_list(term) */\n    if (term & (_TAG_PRIMARY_MASK - TAG_PRIMARY_LIST)) {\n\n        /* Unpack our fail label (lower 32 bits) and add\n         * it to our current instruction pointer. This\n         * is an offset and may be negative for backward\n         * jumps. */\n        I += (Sint32)arg_word;\n\n        /* Jump to the instruction at the fail label using\n         * the \"labels as values\" GCC extension. */\n        goto *I;\n    }\n\n    /* Skip the current label address and argument word,\n     * then jump to the next instruction. This was\n     * automatically generated by beam_makeops. */\n    I += 2;\n    goto *I;\n}\n```\n\nThere's a bit more to it, and those who would like to know more can read the\n[documentation for the `beam_makeops` script], but the above covers the gist of\nit.\n\nWhile the above is quite efficient, there's significant overhead from dispatch\nand argument handling. Here's a slightly altered assembly listing of the\nabove:\n\n<pre class=\"highlight\">\n    <em>; Read the argument word from the instruction\n    ; stream.</em>\n    mov    rdx, [rbx + 8]\n\n    <em>; Unpack the offset of our source register (upper 32\n    ; 32 bits).</em>\n    mov    rcx, rdx\n    shr    rcx, 32\n\n    <em>; X registers live in machine register r15, and we\n    ; placed our offset in rcx, so we can find our term at\n    ; [r15 + rcx].\n    ;\n    ; Perform a non-destructive bitwise AND on the term\n    ; using the `test` instruction, and jump to the fail\n    ; label if the result is non-zero.</em>\n    <b>test   byte [r15 + rcx], (_TAG_PRIMARY_MASK - TAG_PRIMARY_LIST)\n    jne    jump_to_fail_label</b>\n\n    <em>; Skip the current label address and argument word,\n    ; then jump to the next instruction.</em>\n    add    rbx, 16\n    jmp    [rbx]\n\njump_to_fail_label:\n    <em>; Unpack our fail label (lower 32 bits) and add\n    ; it to our current instruction pointer.</em>\n    movsxd rdx, edx\n    lea    rbx, [rbx + rdx * 8]\n\n    <em>; Jump to the instruction at the fail label.</em>\n    jmp    [rbx]\n</pre>\n\nThe bold section is the meat of the instruction and the rest is argument\nunpacking and instruction dispatch. While this is not much of a problem for\nlarge instructions, its effect on short ones like this is very large, and when\nlooking through a profiler (e.g. [`perf`]) it's not unusual for the final `jmp`\nto dominate the rest.\n\nTo lessen this effect, the loader combines commonly used instruction sequences\ninto a single instruction. For example, two independent moves may fuse into\n[`move2_par`], and `is_nonempty_list` followed by `get_list` might be fused to\n[`is_nonempty_list_get_list`].\n\nThis reduces the cost of short instructions, but only works to the extent we're\nable to identify common patterns and comes at a significant maintenance cost\nas each combination must be implemented manually. Even so, the effect tends to\nbe moderate and the dispatch overhead remains significant.\n\nAnother, albeit lesser, downside with the interpreter is that modern processors\nare very optimized for patterns commonly found in \"ordinary\" native code. For\nexample, nearly all of them have a special branch predictor just for calls and\nreturns. Assuming that every call has a corresponding return lets it predict\nreturns _perfectly_ unless an exception is thrown, but since the interpreter\ndoes not use native calls and returns, it cannot make use of this optimization.\n\nUnfortunately there's not a whole lot that can be done about this, and after\nover two decades of refinement it's becoming increasingly difficult to optimize\nit in meaningful ways.\n\nBecause of that our quest to improve performance has instead focused on two\nareas: improving the compiler and implementing a JIT. We've made great strides\nwith both as of late, and are very proud to have finally merged the latter.\n\nStay tuned for our next post, where we'll have a look at the JIT and see how it\navoids these issues.\n\n[directly threaded code]: https://en.wikipedia.org/wiki/Threaded_code\n[`ops.tab`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/ops.tab\n[`beam_makeops`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/utils/beam_makeops\n[documentation for the `beam_makeops` script]: http://erlang.org/doc/apps/erts/beam_makeops.html\n[`move2_par`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L577\n[`is_nonempty_list_get_list`]: https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/instrs.tab#L795\n[`perf`]: https://en.wikipedia.org/wiki/Perf_%28Linux%29\n[earlier post]: http://blog.erlang.org/Interpreter-Optimizations/\n[previous post]: http://blog.erlang.org/a-brief-BEAM-primer/\n"}},"__N_SSG":true}