{"pageProps":{"item":{"id":"beam-compiler-history","title":"A Brief History of the BEAM Compiler","author":"Björn Gustavsson","excerpt":"\nThis blog post is a brief history lesson about the Erlang compiler for\nthe BEAM machine. To provide some context, there will first be a quick\nlook at the abstract machines for Erlang.","article_date":1529280000000,"tags":["compiler BEAM"],"frontmatter":{"layout":"post","title":"A Brief History of the BEAM Compiler","tags":"compiler BEAM","author":"Björn Gustavsson"},"content":"\nThis blog post is a brief history lesson about the Erlang compiler for\nthe BEAM machine. To provide some context, there will first be a quick\nlook at the abstract machines for Erlang.\n\n## A brief overview of the early Erlang implementations\n\n### The Prolog interpreter\n\nThe first version of Erlang was implemented in\nProlog in 1986. That version of Erlang was used\nto find out which features of the languages were\nuseful and which were not. New languages features\ncould be added or deleted in a matter of hours\nor days.\n\n### JAM (Joe's Abstract Machine)\n\nIt soon became clear that Erlang needed to be at\nleast 40 times faster to be useful in real projects.\n\nIn 1989 JAM (Joe's Abstract Machine) was first\nimplemented. [Mike Williams][mike] wrote the runtime system\nin C, [Joe Armstrong][joe] wrote the compiler, and\n[Robert Virding][robert] wrote the libraries.\n\n[mike]: http://www.erlang-factory.com/conference/ErlangUserConference2013/speakers/MikeWilliams\n[joe]: https://github.com/joearms\n[robert]: https://github.com/rvirding\n\nJAM turned out be 70 times faster than the Prolog\ninterpreter. Success?\n\n### TEAM (Turbo Erlang Abstract Machine)\n\nIt soon became clear that Erlang still needed\nto be faster to be useful in real projects.\n\nTherefore Bogumil (\"Bogdan\") Hausman created TEAM (Turbo Erlang\nAbstract Machine). It compiled the Erlang code to C code, which was\nthen compiled to native code using GCC.\n\nIt was significantly faster than JAM for small projects.\nUnfortunately, compilation was very slow, and the code size of the\ncompiled code was too big to make it useful for large projects.\n\n### BEAM (Bogdan's Erlang Abstract Machine)\n\nBogumil Hausman next machine was called BEAM\n(Bogdan's Erlang Abstract Machine). It was a hybrid machine\nthat could execute both native code and [threaded code] with\nan [interpreter]. That allowed customers to compile their\ntime-critial modules to native code and all other modules to\nthreaded BEAM code. The threaded BEAM in itself was faster\nthan JAM code.\n\n[threaded code]: https://en.wikipedia.org/wiki/Threaded_code\n[interpreter]: https://en.wikipedia.org/wiki/Interpreter_(computing)\n\nBogdan's original compiler for BEAM shared the compiler front end with\nJAM. Essentially, the front end at that time did the same thing as the\nfront end in the current compiler as described in [Lost in Translation\n(Exploring the Compiler's Front End)][front end].\n\nI don't have the source code for Bodgan's original compiler,\nbut as far as I can determine it had three compiler passes that\ntranslated the abstract format to threaded BEAM code.\n\n* `beam_compile` - Translated the abstract format to BEAM instructions.\n\n* `beam_optimize` - Optimized the BEAM instructions. This pass was mandatory,\nsince it did some necessary transformations of the BEAM instructions.\n\n* `beam_asm` - Converted the symbolic BEAM assembly format to a binary\nBEAM module.\n\n[front end]: http://blog.erlang.org/compiler-lost-in-translation\n\n### VEE (Virding's Erlang Engine)\n\nHere we must mention VEE (Virding's Erlang Engine) for reasons that\nwill soon become clear.\n\nVEE was an experimental implementation with a different memory model\ncompared to JAM and BEAM. Instead of JAM's and BEAM's separate heaps\nfor each process, VEE used a single shared heap with a real-time\ngarbage collector.  That made message passing blindlingly fast\ncompared to JAM and BEAM.\n\nOverall, though, there was no speed gain compared to JAM. The reason\nwas probably that the single shared heap decreased the cache hit\nrate.\n\n## The maturation of BEAM\n\nThe OTP group and Erlang/OTP was created to industrialize Erlang and\nmake it suitable for huge real-world projects. The first release, OTP\nR1B, was released in 1996.\n\nThis is the point where the history lesson may become a little bit\nmore subjective.\n\nI joined the Erlang/OTP team at the end of 1996. My first small\ncode contributions to Erlang/OTP were included in OTP R1D.\n\nI worked in the ERTS (Erlang Run-Time System) team, which at that time\nwas lead by Kenneth Lundin. Initially I worked with the Erlang runtime\nsystem for Microsoft Windows. After some time (maybe a year or so),\nKenneth asked me to help stabilizing and improving BEAM. Gradually\nBEAM become my main responsibility, and when Bogdan left Ericsson, I\nbecome the main developer responsible for the BEAM [interpreter] and\ncompiler.\n\nThis blog post desperately tries to cover the history of the BEAM\n*compiler*, but I think that some more historical context is needed\nbefore we can approach the compiler.\n\nThe overall goal of the work on BEAM from OTP R1 up to OTP R5\nwas to make it stable enough and fast enough to be useful in real\nprojects.\n\nThere were two major obstacles to reaching that goal:\n\n* BEAM/C, that is, native code via C code.\n* The huge number of ever-changing BEAM instructions.\n\n### BEAM/C must die!\n\nIt soon became obvious that BEAM/C, the compiler passes that\ncompiled Erlang code to C code, had to die. At the time that\nI started working on BEAM, there were three distinct flavors of\nBEAM/C: one for GCC on Sparc, one for GCC on non-sparc CPUs (such\nas Intel x86), and one for other C compilers that did not support\nGCC's extension for taking the address of a label. Bugs not only showed\nup in the native code, but the mere existence of BEAM/C complicated and\ncaused bugs in the threaded BEAM interpreter.\n\nUnfortunately, early in my career of improving BEAM, I made some\noptimizations of the size of the C code generated by BEAM/C. That came\nback to bite me later when I suggested that we should remove\nBEAM/C. The size improvements made it possible to fit more Erlang code\ncompiled to native code into the system, and the native code was\nfaster than threaded BEAM code. Our customer at the time ([the AXD 301\nproject][axd301]) needed the extra speed improvements that BEAM/C gave\nthem and did not allow us to remove BEAM/C unless we could improve the\nperformance of threaded BEAM code to similar or better than BEAM/C\nperformance.\n\n[axd301]: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.9122&rep=rep1&type=pdf\n\n### The ever-changing BEAM instructions\n\nAt that time, the BEAM interpreter had over [300\ninstructions][beam1997].  While JAM had a very simple loader that\nessentially only loaded the JAM files into memory, the loader for BEAM\nhad to translate every instruction from the byte format in the BEAM\nfiles to the threaded code format in memory.  The BEAM had\nhand-written code for the loading of every single instruction.\n\nTo make it worse, the instruction set was constantly evolving. Bug\nfixes and performance improvements needed new instructions, and those\ninstructions had to be implemented in the compiler, threaded code\ninterpreter (the `process_main()` function in `beam_emu.c`), and\nthe loader. In every minor and major release of Erlang/OTP, the\nusers of BEAM had to recompile all of their Erlang code\nbecause the instruction set had changed.\n\nThere must be a better way, I thought. I started to write a simple\nPerl script to a least automate the mapping from instruction name to\ninstruction number in the compiler, interpreter, and loader.\n[Tony Rogvall][tonyrog] suggested that I could be more ambitious and\ngenerate most of the code for for the loader using the Perl script.\nHe also suggested that operands for many instructions could be packed\ninto a single word. That would reduce load code size and also improve\nthe cache hit rate, improving execution speed.\n\nSo I started writing the first version of the [beam_makeops script][makeops]\nand rewriting the loader. I prefer to work incrementally, making minor changes\nto a code base that is always working. But I could not rewrite the loader\nincrementally, so I hacked away frantically for two or three days until\nI had a bare bones version of the new loader working. I could then relax\na little and somewhat more slowly add more features to `beam_makeops` and\nthe loader.\n\nThe new loader took over some tasks formerly done by the compiler.\n\nFor example, the BEAM machine has several specialized `move`\ninstructions.  There is one instruction for moving something into an X\nregister, another for moving an atom into an X register, and so\non. Before the new loader, the compiler knew about all those variants\nof `move` instructions and selected the appropriate one. With the new\nloader, there is only one `move` instruction that the compiler needs\nto care about, and the loader will select the appropriate specialized\n`move` instruction to use at load time.\n\nAnother minor optimization done by the compiler was combining of\ncommon instructions sequences. For example, a `move` instruction\nfollowed by a `call` instruction would be combined to a `move_call`\ninstruction. That optimization was also moved to the loader.\n\nAll those capabilities made it possible to significantly simplify and\nreduce the number of instructions known to the compiler. More\nimportantly, that made it possible to keep the instruction set stable\n(while still allowing minor optimizations and performance tuning by\ntweaking only the loader and interpreter), avoiding the need to\nrecompile all Erlang code every time there was a new release.\n\nIf my memory doesn't fail me, the new loader was introduced in OTP R4.\n\n[beam1997]: http://www.cs-lab.org/historical_beam_instruction_set.html\n[tonyrog]: https://github.com/tonyrog\n[makeops]: https://github.com/erlang/otp/blob/OTP-21.0-rc1/erts/emulator/internal_doc/beam_makeops.md\n\n## OTP R5B: The \"new\" BEAM\n\nMoving forward to OTP R5.\n\nOTP R5 was the last release that supported JAM.\n\nOTP R5 can also be said to be first release that featured the \"new\"\nBEAM. In that release, the [modern BEAM file format][beam file format]\nwas introduced. The same file format is used today. At that time,\nthere were 78 BEAM instructions; in OTP 20, there are 159 instructions\n(actually, 129 active instructions and 30 obsoleted instructions no\nlonger used). While new instructions have been introduced when needed\nand obsolete instructions have been removed, it has always been\npossible to load BEAM files compiled from at least two major releases\nback.\n\nExecution of threaded BEAM had become fast enough, so that BEAM/C\ncould be dropped (already in R4, I think). But strangely enough,\nthe customers still wanted more speed.\n\nThe BEAM compiler in R5 was still Bogdan's original compiler. While\nit did more optimizations than the JAM ever did, we knew that more\noptimizations were possible.\n\n[beam file format]: http://www.erlang.se/~bjorn/beam_file_format.html\n\n## R6B: Enter Kernel Erlang\n\nMeanwhile, on the top floor Robert Virding was busy writing a\nnew compiler for his VEE machine. In that new compiler, Robert\nintroduced a new intermediate format that he called *Kernel Erlang*.\nThe idea was that more optimizations could be applied to the code\nin that format before generating code for the actual machine.\n\nAt that time, there was no actual interpreter that could execute the\ncode emitted by his new compiler (he had not updated the VEE machine\nyet). The machine he had in mind was a register machine. It was similar\nto BEAM, except that it did stack trimming.\n\nWe wanted the better performance that we could get from Robert's compiler,\nbut the question was: should we implement a new interpreter (or adapt\nBEAM) to execute the code from Robert's compiler, or should we adapt\nRobert's compiler to generate BEAM code?\n\nBecause we now for the first time had a stable implementation of BEAM,\nwe decided not to rock the boat again; thus, we decided that I should\nadapt the code generator part of Robert's compiler for BEAM.\n\nFor the most part, I used Robert's name for instructions. For example,\nthe instruction to load a term into a register was called `M` in the\noriginal BEAM, while Robert's compiler used the `move`. The more major\nchanges was in the handling of the stack.  Robert's compiler had stack\ntrimming, which I had to remove and rewrite to handle BEAM's fixed\nstack frame. (I reintroduced a limited form of stack trimming later.)\n\nSince JAM was not supported in OTP R6, all customers that had previously\nused JAM had to migrate to BEAM. To minimize the risk of the migration\nas much as possible, one of our customers requested that we made the\nbattle-tested original BEAM compiler available as an option in OTP R6.\n\nTherefore, we added options to choose which version of the compiler\nto use. To use the old compiler, one would write:\n\n```\n$ erlc +v1 some_module.erl\n```\n\nDefault was Robert's new compiler, which was called `v2`. There\nwas also an undocumented, unofficial compiler version called `v3`.\n\nAll compilers shared the front end and the `beam_asm` pass that\ncreated the final BEAM module.\n\n### The v1_compiler\n\nThe `v1` compiler had the following passes:\n\n* v1_adapt\n* v1_compile\n* v1_optimize\n* v1_cleanup\n\nThe `v1_compile` and `v1_optimize` passes were essentially\nthe `beam_compile` and `beam_optimize` passes from Bogdan's\ncompiler.\n\nThere had been some changes to the front end since R5, so\nthe `v1_adapt` pass was there to hide those changes for the\n`v1_compile` and `v1_optimize` passes. The `v1_cleanup` pass was\nan additional minor optimization pass; I think it was present\nin OTP R5 as well.\n\n### The v2_compiler\n\nThe `v2` compiler was Robert's new compiler. It had the following\npasses:\n\n* v2_kernel\n* v2_kernopt\n* v2_match\n* v2_life\n* v2_codegen\n\nThe `v2_kernel` pass translated the abstract format to Kernel Erlang.\n\n`v2_kernopt` did very basic optimizations of the Kernel Erlang code,\nessentially only [constant propagation and constant folding][folding].\n\n`v2_match` did pattern matching compilation. JAM would match clauses\nin function heads or `case` expressions sequentially. The old BEAM\ncompiler would do only a little bit better in that it could match\nmultiple integers or atoms in a single instruction. Robert's compiler\nwas the first Erlang compiler to properly compile pattern matching using\nthe algorithm described in\n[The Implementation of Functional Programming Languages][peytonjones]\nby Simon Peyton Jones.\n\n`v2_life` would calculate life-time information needed by the\n`v2_codegen` pass, and `v2_codegen` would generate the BEAM\nassembly code.\n\n[folding]: https://en.wikipedia.org/wiki/Constant_folding\n[peytonjones]: https://www.microsoft.com/en-us/research/publication/the-implementation-of-functional-programming-languages/\n\n## R7B: Enter Core Erlang\n\nMeanwhile, [Richard Carlsson][carlsson] and the [HiPE group][hipe]\nat Uppsala University come up with the idea for a new intermediate\nformat useful as an interchange format for different Erlang\nimplementations and for optimizing Erlang programs.\n\nThe new format was called [Core Erlang][core]. Robert liked the idea\nand started to implement Core Erlang in the compiler.  The undocumented\nimplementation of `v3` compiler in OTP R6 is based on a draft version\nof the Core Erlang specification.\n\nIn OTP R7B, the v1 and v2 compilers were removed, and the only\nremaining compiler was the `v3` compiler that used Core Erlang.\nIt had the following passes:\n\n* v3_core\n* v3_core_opt\n* v3_kernel\n* v3_life\n* v3_codegen\n\nThe `v3_core` pass translated the abstract format to Core Erlang.\n\nThe `v3_core_opt` pass essentially only called `sys_core_fold`, which\ndid [constant propagation and constant folding][folding]. `sys_core_fold`\nstill do those things, and [more][sys_core_fold].\n\nThe remaining passes do the same thing as today.\n\nThe `v3_kernel` pass translates from Core Erlang to Kernel Erlang,\nand also does pattern matching compilation (in the same way as in\n`v2_match`). The optimizations in `v2_kernopt` are now done in\n`sys_core_fold`.\n\nThe `v3_life` pass (despite its name) no longer calculates life-time\ninformation. The life-time information is instead calculated by\n`v3_kernel` and passed on as annotations.\n\nThe reason that `v3_life` still exists is that Robert had continued\nto work on his own version of `codegen` that did not have all\nmy changes in it to work for BEAM. While implementing the Core Erlang\npasses, he also did many improvements to `codegen`.\n\nWhen it was time to integrate our different versions of the compiler,\nRobert looked in horror at all my changes in `codegen`. To avoid\nhaving to reintroduce all my adapations and optimizations for BEAM\ninto his new version of `codegen`, Robert wrote an adapter pass\nthat translated from the new Kernel Erlang format to the old format\nso that my `codegen` would work. The adapter pass is called\n`v3_life`.\n\nThus, `v3_codegen` is essentially `v2_codegen` with a new name.\n\nIn the upcoming OTP 21, `v3_life` has been combined with `v3_codegen`.\n\n[hipe]: https://www.it.uu.se/research/group/hipe/\n[carlsson]: https://github.com/richcarl\n[core]: https://www.it.uu.se/research/group/hipe/cerl/doc/core_erlang-1.0.3.pdf\n[sys_core_fold]: http://blog.erlang.org/core-erlang-optimizations\n\n## Learning Erlang from Robert\n\nIn the time period that Robert and I worked together on the compiler,\nI usually worked on `v3_codegen` and the passes below, while Robert\nworked on all passes above `v3_codegen`.\n\nOccasionally, I would add some optimizations to `sys_core_fold` and\ngive them to Robert to incorporate into his latest version of\n`sys_core_fold`.\n\nI would then look at what Robert had done with my code, and learn.\n\nUsually Robert had subtly improved my code, made it slightly\ncleaner and simpler. But one time I handed Robert an\noptimization of `case` clauses. The code I got back was very different.\nRobert had broken apart my optimization into several simpler\noptimizations that achieved the same purpose (and more) than my\nmore complicated optimization.\n"}},"__N_SSG":true}